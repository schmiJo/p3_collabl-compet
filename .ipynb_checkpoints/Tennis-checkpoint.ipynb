{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collaboration and Competition\n",
    "\n",
    "---\n",
    "\n",
    "In this notebook, you will learn how to use the Unity ML-Agents environment for the third project of the [Deep Reinforcement Learning Nanodegree](https://www.udacity.com/course/deep-reinforcement-learning-nanodegree--nd893) program.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make imports and create the agent and the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:unityagents:\n",
      "'Academy' started successfully!\n",
      "Unity Academy name: Academy\n",
      "        Number of Brains: 1\n",
      "        Number of External Brains : 1\n",
      "        Lesson number : 0\n",
      "        Reset Parameters :\n",
      "\t\t\n",
      "Unity brain name: TennisBrain\n",
      "        Number of Visual Observations (per agent): 0\n",
      "        Vector Observation space type: continuous\n",
      "        Vector Observation space size (per agent): 8\n",
      "        Number of stacked Vector Observation: 3\n",
      "        Vector Action space type: continuous\n",
      "        Vector Action space size (per agent): 2\n",
      "        Vector Action descriptions: , \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of agents: 2\n",
      "Size of each action: 2\n",
      "There are 2 agents. Each observes a state with length: 24\n",
      "The state for the first agent looks like: [ 0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.         -6.65278625 -1.5\n",
      " -0.          0.          6.83172083  6.         -0.          0.        ]\n"
     ]
    }
   ],
   "source": [
    "from unityagents import UnityEnvironment\n",
    "import numpy as np\n",
    "\n",
    "env = UnityEnvironment(file_name=\"./Tennis.app\")\n",
    "\n",
    "# get the default brain\n",
    "brain_name = env.brain_names[0]\n",
    "brain = env.brains[brain_name]\n",
    "\n",
    "# reset the environment\n",
    "env_info = env.reset(train_mode=True)[brain_name]\n",
    "\n",
    "# number of agents \n",
    "num_agents = len(env_info.agents)\n",
    "print('Number of agents:', num_agents)\n",
    "\n",
    "# size of each action\n",
    "action_size = brain.vector_action_space_size\n",
    "print('Size of each action:', action_size)\n",
    "\n",
    "# examine the state space \n",
    "states = env_info.vector_observations\n",
    "state_size = states.shape[1]\n",
    "print('There are {} agents. Each observes a state with length: {}'.format(states.shape[0], state_size))\n",
    "print('The state for the first agent looks like:', states[0])\n",
    "\n",
    "import numpy as np\n",
    "from collections import deque\n",
    "import matplotlib.pyplot as plt\n",
    "from agent import AgentList\n",
    "\n",
    "agents = AgentList(state_size= 24, action_size=2, agents_count = 2, random_seed = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 100\tavg Score: 0.00\n",
      "Episode 200\tavg Score: 0.00\n",
      "Episode 300\tavg Score: 0.00\n",
      "Episode 400\tavg Score: 0.00\n",
      "Episode 500\tavg Score: 0.00\n",
      "Episode 600\tavg Score: 0.01\n",
      "Episode 700\tavg Score: 0.00\n",
      "Episode 800\tavg Score: 0.00\n",
      "Episode 900\tavg Score: 0.00\n",
      "Episode 1000\tavg Score: 0.00\n",
      "Episode 1100\tavg Score: 0.01\n",
      "Episode 1200\tavg Score: 0.00\n",
      "Episode 1300\tavg Score: 0.02\n",
      "Episode 1400\tavg Score: 0.01\n",
      "Episode 1500\tavg Score: 0.02\n",
      "Episode 1600\tavg Score: 0.04\n",
      "Episode 1700\tavg Score: 0.09\n",
      "Episode 1800\tavg Score: 0.17\n",
      "Episode 1900\tavg Score: 0.18\n",
      "Episode 2000\tavg Score: 0.13\n",
      "Episode 2100\tavg Score: 1.14\n",
      "Episode 2187\tavg Score: 1.41\n",
      "Environment solved in 2187 episodes!\tAverage Score: 1.41\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "def ddpg(n_episodes: int =  6000, max_actions:int = 15000 ):\n",
    "    scores = []\n",
    "    scores_window= deque(maxlen=100)\n",
    "    \n",
    "    \n",
    "    for i_episode in range(1,n_episodes+1):\n",
    "        \n",
    "        #reset the environment for every episode and initialize the state\n",
    "        #step_brain_info = env.reset(train_mode=i_episode % 100 != 0)[brain_name] # reset the environment\n",
    "        step_brain_info = env.reset(train_mode=True)[brain_name] # reset the environment\n",
    "        \n",
    "        agents.reset_noise()\n",
    "        \n",
    "        states = step_brain_info.vector_observations   #obtain the starting state\n",
    "        \n",
    "        score_0 = 0 #initialze the score for the episode\n",
    "        score_1 = 0 #initialze the score for the episode\n",
    "        \n",
    "        \n",
    "        for a in range(max_actions):\n",
    "            \n",
    "            #The agent chooses an action\n",
    "            # after 200 episodes the actor should not add noise to the action to create a more stable agent\n",
    "            actions = agents.act(states, add_noise=i_episode < 1000)\n",
    "            \n",
    "            step_brain_info = env.step(actions)[brain_name]\n",
    "            \n",
    "            next_states: np.ndarray = step_brain_info.vector_observations   # get the next state\n",
    "            rewards = step_brain_info.rewards                   # get the reward\n",
    "            dones = step_brain_info.local_done                  # see if episode has finished\n",
    "            \n",
    "            score_0 += rewards[0]\n",
    "            score_1 += rewards[1]\n",
    "            \n",
    "            #Take a step and learn from the s,a,r,s,d pair\n",
    "            agents.step(states, actions, rewards, next_states, dones)\n",
    "             \n",
    "            states = next_states                             # roll over the state to next time step\n",
    "            if agents.is_all_done(dones):                             # exit loop if episode finished\n",
    "                break\n",
    "                \n",
    "            if env.global_done:\n",
    "                print('Global Done Steps: '+ str(a))\n",
    "                break\n",
    "        \n",
    "        bigger_score = max([score_0, score_1])\n",
    "        scores.append(bigger_score)\n",
    "        scores_window.append(bigger_score)       # save most recent score\n",
    "\n",
    "        \n",
    "        print('\\rEpisode {}\\tavg Score: {:.2f}'.format(i_episode, np.mean(scores_window)), end=\"\")\n",
    "        \n",
    "        if i_episode % 100 == 0:\n",
    "            print('\\rEpisode {}\\tavg Score: {:.2f}'.format(i_episode, np.mean(scores_window)))\n",
    "        if np.mean(scores_window)>=1.4:\n",
    "            print('\\nEnvironment solved in {:d} episodes!\\tAverage Score: {:.2f}'.format(i_episode, np.mean(scores_window)))\n",
    "            #torch.save(agent.qnetwork_local.state_dict(), 'checkpoint.pth')\n",
    "            break\n",
    "            \n",
    "    \n",
    "    return scores\n",
    "            \n",
    "    \n",
    "scores =  ddpg()\n",
    "# plot the scores\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "plt.plot(np.arange(len(scores)), scores)\n",
    "plt.ylabel('Score')\n",
    "plt.xlabel('Episode #')\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the weights\n",
    "agents.save_state()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# See the trained agent in action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# restore weights\n",
    "agents.restore_state()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "n_episodes = 2\n",
    "for i_episode in range(1,n_episodes+1):\n",
    "      #reset the environment for every episode and initialize the state\n",
    "    #step_brain_info = env.reset(train_mode=i_episode % 100 != 0)[brain_name] # reset the environment\n",
    "    step_brain_info = env.reset(train_mode=False)[brain_name] # reset the environment\n",
    "        \n",
    "    agents.reset_noise()\n",
    "        \n",
    "    states = step_brain_info.vector_observations   #obtain the starting state\n",
    "        \n",
    "    score_0 = 0 #initialze the score for the episode\n",
    "    score_1 = 0 #initialze the score for the episode\n",
    "        \n",
    "        \n",
    "    for a in range(5000):\n",
    "            \n",
    "        #The agent chooses an action\n",
    "        # after 200 episodes the actor should not add noise to the action to create a more stable agent\n",
    "        actions = agents.act(states, add_noise=i_episode < 1000)\n",
    "            \n",
    "        step_brain_info = env.step(actions)[brain_name]\n",
    "            \n",
    "        next_states: np.ndarray = step_brain_info.vector_observations   # get the next state\n",
    "        rewards = step_brain_info.rewards                   # get the reward\n",
    "        dones = step_brain_info.local_done                  # see if episode has finished\n",
    "            \n",
    "        score_0 += rewards[0]\n",
    "        score_1 += rewards[1]\n",
    "        \n",
    "        #Take a step and learn from the s,a,r,s,d pair\n",
    "        agents.step(states, actions, rewards, next_states, dones)\n",
    "         \n",
    "        states = next_states                             # roll over the state to next time step\n",
    "        if agents.is_all_done(dones):                             # exit loop if episode finished\n",
    "            break\n",
    "            \n",
    "        if env.global_done:\n",
    "            print('Global Done Steps: '+ str(a))\n",
    "            break\n",
    "            \n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "drlnd",
   "language": "python",
   "name": "drlnd"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
